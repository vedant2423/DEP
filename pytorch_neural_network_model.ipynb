{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9f6bb8",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (ANN) Model with PyTorch for FFT Features Dataset\n",
    "\n",
    "This notebook builds an Artificial Neural Network (ANN) model using PyTorch and the FFT features dataset from the Raw_data directory. It includes:\n",
    "\n",
    "1. Data loading and exploration\n",
    "2. Data preprocessing and normalization\n",
    "3. Data splitting (60% training, 20% validation, 20% test) with random shuffling\n",
    "4. Feature selection interface\n",
    "5. PyTorch neural network model building with customizable parameters\n",
    "6. Model training and evaluation\n",
    "7. Performance visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513b5de",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Import the necessary libraries for data processing, PyTorch neural network modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ae772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# Interactive widgets for feature selection\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Set plotting styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#use apple metal \n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# Print the device being used\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f0bc5c",
   "metadata": {},
   "source": [
    "## Load and Explore the Dataset\n",
    "\n",
    "Load the FFT features dataset from the Raw_data directory and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb05304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with shape: (2792, 37)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the FFT features dataset\n",
    "file_path = '/Users/vedantgupta/Documents/project /DEP-1/data/Raw_data/fft_features_dataset.csv'\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Dataset loaded successfully with shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "    # Create a sample dataset for demonstration if the file is not found\n",
    "    print(\"Creating sample data for demonstration...\")\n",
    "    np.random.seed(42)\n",
    "    n_samples = 200\n",
    "    window_ids = np.arange(n_samples)\n",
    "    features = {f'feature_{i}': np.random.normal(0, 1, n_samples) + i * np.sin(window_ids/10) for i in range(1, 11)}\n",
    "    features['window_id'] = window_ids\n",
    "    # Add a label column for classification\n",
    "    features['label'] = np.random.randint(0, 3, n_samples)\n",
    "    df = pd.DataFrame(features)\n",
    "    print(f\"Sample dataset created with shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "739bf9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fft_total_energy</th>\n",
       "      <th>fft_spectral_kurtosis</th>\n",
       "      <th>fft_spectral_skewness</th>\n",
       "      <th>fft_spectral_entropy</th>\n",
       "      <th>fft_peak_freq</th>\n",
       "      <th>fft_peak_amplitude</th>\n",
       "      <th>fft_bpfo_1x_energy</th>\n",
       "      <th>fft_bpfo_1x_peak</th>\n",
       "      <th>fft_bpfo_2x_energy</th>\n",
       "      <th>fft_bpfo_2x_peak</th>\n",
       "      <th>...</th>\n",
       "      <th>cur_bpfo_3x_peak</th>\n",
       "      <th>cur_bpfo_1x_upper_sideband</th>\n",
       "      <th>cur_bpfo_1x_lower_sideband</th>\n",
       "      <th>cur_bpfo_harmonic_ratio</th>\n",
       "      <th>cur_spectral_centroid</th>\n",
       "      <th>vib_cur_coherence</th>\n",
       "      <th>window_id</th>\n",
       "      <th>op_freq</th>\n",
       "      <th>BPFO</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014995</td>\n",
       "      <td>342.624687</td>\n",
       "      <td>18.090283</td>\n",
       "      <td>4.694671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108815</td>\n",
       "      <td>7.228981e-07</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>2.234853e-06</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130098</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.056649</td>\n",
       "      <td>0.151708</td>\n",
       "      <td>987.250669</td>\n",
       "      <td>0.263249</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>55.478927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015267</td>\n",
       "      <td>342.272195</td>\n",
       "      <td>18.079856</td>\n",
       "      <td>4.654710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>1.037048e-06</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>2.603617e-06</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129736</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.036215</td>\n",
       "      <td>0.149443</td>\n",
       "      <td>928.036659</td>\n",
       "      <td>0.344890</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>55.478927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015125</td>\n",
       "      <td>342.920462</td>\n",
       "      <td>18.097394</td>\n",
       "      <td>4.723438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109293</td>\n",
       "      <td>1.068530e-06</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>1.761568e-06</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116732</td>\n",
       "      <td>0.013051</td>\n",
       "      <td>0.066224</td>\n",
       "      <td>0.153472</td>\n",
       "      <td>1040.339770</td>\n",
       "      <td>0.297090</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>55.478927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014857</td>\n",
       "      <td>343.150759</td>\n",
       "      <td>18.105364</td>\n",
       "      <td>4.671007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108391</td>\n",
       "      <td>2.700607e-06</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>1.570791e-06</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137694</td>\n",
       "      <td>0.018121</td>\n",
       "      <td>0.104149</td>\n",
       "      <td>0.188753</td>\n",
       "      <td>1021.711818</td>\n",
       "      <td>0.250239</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>55.478927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015114</td>\n",
       "      <td>342.541083</td>\n",
       "      <td>18.087168</td>\n",
       "      <td>4.629760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109290</td>\n",
       "      <td>9.345048e-07</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>5.874055e-07</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120735</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.120505</td>\n",
       "      <td>0.194232</td>\n",
       "      <td>1039.540433</td>\n",
       "      <td>0.232888</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>55.478927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fft_total_energy  fft_spectral_kurtosis  fft_spectral_skewness  \\\n",
       "0          0.014995             342.624687              18.090283   \n",
       "1          0.015267             342.272195              18.079856   \n",
       "2          0.015125             342.920462              18.097394   \n",
       "3          0.014857             343.150759              18.105364   \n",
       "4          0.015114             342.541083              18.087168   \n",
       "\n",
       "   fft_spectral_entropy  fft_peak_freq  fft_peak_amplitude  \\\n",
       "0              4.694671            0.0            0.108815   \n",
       "1              4.654710            0.0            0.109795   \n",
       "2              4.723438            0.0            0.109293   \n",
       "3              4.671007            0.0            0.108391   \n",
       "4              4.629760            0.0            0.109290   \n",
       "\n",
       "   fft_bpfo_1x_energy  fft_bpfo_1x_peak  fft_bpfo_2x_energy  fft_bpfo_2x_peak  \\\n",
       "0        7.228981e-07          0.000522        2.234853e-06          0.000879   \n",
       "1        1.037048e-06          0.000453        2.603617e-06          0.001005   \n",
       "2        1.068530e-06          0.000636        1.761568e-06          0.000613   \n",
       "3        2.700607e-06          0.000783        1.570791e-06          0.000807   \n",
       "4        9.345048e-07          0.000651        5.874055e-07          0.000519   \n",
       "\n",
       "   ...  cur_bpfo_3x_peak  cur_bpfo_1x_upper_sideband  \\\n",
       "0  ...          0.130098                    0.010411   \n",
       "1  ...          0.129736                    0.006357   \n",
       "2  ...          0.116732                    0.013051   \n",
       "3  ...          0.137694                    0.018121   \n",
       "4  ...          0.120735                    0.020045   \n",
       "\n",
       "   cur_bpfo_1x_lower_sideband  cur_bpfo_harmonic_ratio  cur_spectral_centroid  \\\n",
       "0                    0.056649                 0.151708             987.250669   \n",
       "1                    0.036215                 0.149443             928.036659   \n",
       "2                    0.066224                 0.153472            1040.339770   \n",
       "3                    0.104149                 0.188753            1021.711818   \n",
       "4                    0.120505                 0.194232            1039.540433   \n",
       "\n",
       "   vib_cur_coherence  window_id  op_freq       BPFO  label  \n",
       "0           0.263249          0       20  55.478927      0  \n",
       "1           0.344890          1       20  55.478927      0  \n",
       "2           0.297090          2       20  55.478927      0  \n",
       "3           0.250239          3       20  55.478927      0  \n",
       "4           0.232888          4       20  55.478927      0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2792 entries, 0 to 2791\n",
      "Data columns (total 37 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   fft_total_energy            2792 non-null   float64\n",
      " 1   fft_spectral_kurtosis       2792 non-null   float64\n",
      " 2   fft_spectral_skewness       2792 non-null   float64\n",
      " 3   fft_spectral_entropy        2792 non-null   float64\n",
      " 4   fft_peak_freq               2792 non-null   float64\n",
      " 5   fft_peak_amplitude          2792 non-null   float64\n",
      " 6   fft_bpfo_1x_energy          2792 non-null   float64\n",
      " 7   fft_bpfo_1x_peak            2792 non-null   float64\n",
      " 8   fft_bpfo_2x_energy          2792 non-null   float64\n",
      " 9   fft_bpfo_2x_peak            2792 non-null   float64\n",
      " 10  fft_bpfo_3x_energy          2792 non-null   float64\n",
      " 11  fft_bpfo_3x_peak            2792 non-null   float64\n",
      " 12  fft_bpfo_1x_upper_sideband  2792 non-null   float64\n",
      " 13  fft_bpfo_1x_lower_sideband  2792 non-null   float64\n",
      " 14  fft_bpfo_harmonic_ratio     2792 non-null   float64\n",
      " 15  fft_spectral_centroid       2792 non-null   float64\n",
      " 16  cur_total_energy            2792 non-null   float64\n",
      " 17  cur_spectral_kurtosis       2792 non-null   float64\n",
      " 18  cur_spectral_skewness       2792 non-null   float64\n",
      " 19  cur_spectral_entropy        2792 non-null   float64\n",
      " 20  cur_peak_freq               2792 non-null   float64\n",
      " 21  cur_peak_amplitude          2792 non-null   float64\n",
      " 22  cur_bpfo_1x_energy          2792 non-null   float64\n",
      " 23  cur_bpfo_1x_peak            2792 non-null   float64\n",
      " 24  cur_bpfo_2x_energy          2792 non-null   float64\n",
      " 25  cur_bpfo_2x_peak            2792 non-null   float64\n",
      " 26  cur_bpfo_3x_energy          2792 non-null   float64\n",
      " 27  cur_bpfo_3x_peak            2792 non-null   float64\n",
      " 28  cur_bpfo_1x_upper_sideband  2792 non-null   float64\n",
      " 29  cur_bpfo_1x_lower_sideband  2792 non-null   float64\n",
      " 30  cur_bpfo_harmonic_ratio     2792 non-null   float64\n",
      " 31  cur_spectral_centroid       2792 non-null   float64\n",
      " 32  vib_cur_coherence           2792 non-null   float64\n",
      " 33  window_id                   2792 non-null   int64  \n",
      " 34  op_freq                     2792 non-null   int64  \n",
      " 35  BPFO                        2792 non-null   float64\n",
      " 36  label                       2792 non-null   int64  \n",
      "dtypes: float64(34), int64(3)\n",
      "memory usage: 807.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in the dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fft_total_energy              0\n",
       "fft_spectral_kurtosis         0\n",
       "fft_spectral_skewness         0\n",
       "fft_spectral_entropy          0\n",
       "fft_peak_freq                 0\n",
       "fft_peak_amplitude            0\n",
       "fft_bpfo_1x_energy            0\n",
       "fft_bpfo_1x_peak              0\n",
       "fft_bpfo_2x_energy            0\n",
       "fft_bpfo_2x_peak              0\n",
       "fft_bpfo_3x_energy            0\n",
       "fft_bpfo_3x_peak              0\n",
       "fft_bpfo_1x_upper_sideband    0\n",
       "fft_bpfo_1x_lower_sideband    0\n",
       "fft_bpfo_harmonic_ratio       0\n",
       "fft_spectral_centroid         0\n",
       "cur_total_energy              0\n",
       "cur_spectral_kurtosis         0\n",
       "cur_spectral_skewness         0\n",
       "cur_spectral_entropy          0\n",
       "cur_peak_freq                 0\n",
       "cur_peak_amplitude            0\n",
       "cur_bpfo_1x_energy            0\n",
       "cur_bpfo_1x_peak              0\n",
       "cur_bpfo_2x_energy            0\n",
       "cur_bpfo_2x_peak              0\n",
       "cur_bpfo_3x_energy            0\n",
       "cur_bpfo_3x_peak              0\n",
       "cur_bpfo_1x_upper_sideband    0\n",
       "cur_bpfo_1x_lower_sideband    0\n",
       "cur_bpfo_harmonic_ratio       0\n",
       "cur_spectral_centroid         0\n",
       "vib_cur_coherence             0\n",
       "window_id                     0\n",
       "op_freq                       0\n",
       "BPFO                          0\n",
       "label                         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fft_total_energy</th>\n",
       "      <th>fft_spectral_kurtosis</th>\n",
       "      <th>fft_spectral_skewness</th>\n",
       "      <th>fft_spectral_entropy</th>\n",
       "      <th>fft_peak_freq</th>\n",
       "      <th>fft_peak_amplitude</th>\n",
       "      <th>fft_bpfo_1x_energy</th>\n",
       "      <th>fft_bpfo_1x_peak</th>\n",
       "      <th>fft_bpfo_2x_energy</th>\n",
       "      <th>fft_bpfo_2x_peak</th>\n",
       "      <th>...</th>\n",
       "      <th>cur_bpfo_3x_peak</th>\n",
       "      <th>cur_bpfo_1x_upper_sideband</th>\n",
       "      <th>cur_bpfo_1x_lower_sideband</th>\n",
       "      <th>cur_bpfo_harmonic_ratio</th>\n",
       "      <th>cur_spectral_centroid</th>\n",
       "      <th>vib_cur_coherence</th>\n",
       "      <th>window_id</th>\n",
       "      <th>op_freq</th>\n",
       "      <th>BPFO</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.0</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2.792000e+03</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2.792000e+03</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.0000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>2792.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.027710</td>\n",
       "      <td>339.939834</td>\n",
       "      <td>17.977223</td>\n",
       "      <td>4.958092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143229</td>\n",
       "      <td>1.266898e-05</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>1.468516e-05</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145489</td>\n",
       "      <td>0.014683</td>\n",
       "      <td>0.297987</td>\n",
       "      <td>0.095571</td>\n",
       "      <td>946.278007</td>\n",
       "      <td>0.124409</td>\n",
       "      <td>1395.5000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>76.283525</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011633</td>\n",
       "      <td>3.063089</td>\n",
       "      <td>0.120740</td>\n",
       "      <td>0.286626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030543</td>\n",
       "      <td>1.453897e-05</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>1.876124e-05</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198179</td>\n",
       "      <td>0.027505</td>\n",
       "      <td>0.210198</td>\n",
       "      <td>0.080226</td>\n",
       "      <td>105.087835</td>\n",
       "      <td>0.060938</td>\n",
       "      <td>806.1253</td>\n",
       "      <td>5.591171</td>\n",
       "      <td>15.509609</td>\n",
       "      <td>0.50009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.013998</td>\n",
       "      <td>329.938081</td>\n",
       "      <td>17.637858</td>\n",
       "      <td>4.413572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105274</td>\n",
       "      <td>1.898596e-07</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.308771e-07</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>772.918722</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>55.478927</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.016074</td>\n",
       "      <td>337.335230</td>\n",
       "      <td>17.869816</td>\n",
       "      <td>4.678023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112684</td>\n",
       "      <td>1.335768e-06</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>1.545953e-06</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023167</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.117375</td>\n",
       "      <td>0.028959</td>\n",
       "      <td>844.060068</td>\n",
       "      <td>0.071078</td>\n",
       "      <td>697.7500</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>65.881226</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.027324</td>\n",
       "      <td>340.807936</td>\n",
       "      <td>18.021694</td>\n",
       "      <td>4.972106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144093</td>\n",
       "      <td>3.723791e-06</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>4.153448e-06</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052068</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.236918</td>\n",
       "      <td>0.062344</td>\n",
       "      <td>915.536189</td>\n",
       "      <td>0.111647</td>\n",
       "      <td>1395.5000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>76.283525</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.039316</td>\n",
       "      <td>342.682989</td>\n",
       "      <td>18.090438</td>\n",
       "      <td>5.240967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173676</td>\n",
       "      <td>2.117723e-05</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>2.143827e-05</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175872</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.481420</td>\n",
       "      <td>0.185259</td>\n",
       "      <td>1056.887578</td>\n",
       "      <td>0.174195</td>\n",
       "      <td>2093.2500</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>86.685824</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.042845</td>\n",
       "      <td>345.123374</td>\n",
       "      <td>18.153828</td>\n",
       "      <td>5.361321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>1.127561e-04</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>1.042674e-04</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693436</td>\n",
       "      <td>0.220881</td>\n",
       "      <td>0.744812</td>\n",
       "      <td>0.250326</td>\n",
       "      <td>1121.710932</td>\n",
       "      <td>0.344890</td>\n",
       "      <td>2791.0000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>97.088123</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fft_total_energy  fft_spectral_kurtosis  fft_spectral_skewness  \\\n",
       "count       2792.000000            2792.000000            2792.000000   \n",
       "mean           0.027710             339.939834              17.977223   \n",
       "std            0.011633               3.063089               0.120740   \n",
       "min            0.013998             329.938081              17.637858   \n",
       "25%            0.016074             337.335230              17.869816   \n",
       "50%            0.027324             340.807936              18.021694   \n",
       "75%            0.039316             342.682989              18.090438   \n",
       "max            0.042845             345.123374              18.153828   \n",
       "\n",
       "       fft_spectral_entropy  fft_peak_freq  fft_peak_amplitude  \\\n",
       "count           2792.000000         2792.0         2792.000000   \n",
       "mean               4.958092            0.0            0.143229   \n",
       "std                0.286626            0.0            0.030543   \n",
       "min                4.413572            0.0            0.105274   \n",
       "25%                4.678023            0.0            0.112684   \n",
       "50%                4.972106            0.0            0.144093   \n",
       "75%                5.240967            0.0            0.173676   \n",
       "max                5.361321            0.0            0.181421   \n",
       "\n",
       "       fft_bpfo_1x_energy  fft_bpfo_1x_peak  fft_bpfo_2x_energy  \\\n",
       "count        2.792000e+03       2792.000000        2.792000e+03   \n",
       "mean         1.266898e-05          0.001862        1.468516e-05   \n",
       "std          1.453897e-05          0.001409        1.876124e-05   \n",
       "min          1.898596e-07          0.000228        1.308771e-07   \n",
       "25%          1.335768e-06          0.000657        1.545953e-06   \n",
       "50%          3.723791e-06          0.001172        4.153448e-06   \n",
       "75%          2.117723e-05          0.002935        2.143827e-05   \n",
       "max          1.127561e-04          0.007264        1.042674e-04   \n",
       "\n",
       "       fft_bpfo_2x_peak  ...  cur_bpfo_3x_peak  cur_bpfo_1x_upper_sideband  \\\n",
       "count       2792.000000  ...       2792.000000                 2792.000000   \n",
       "mean           0.001886  ...          0.145489                    0.014683   \n",
       "std            0.001482  ...          0.198179                    0.027505   \n",
       "min            0.000204  ...          0.004878                    0.000042   \n",
       "25%            0.000715  ...          0.023167                    0.000471   \n",
       "50%            0.001200  ...          0.052068                    0.001026   \n",
       "75%            0.002709  ...          0.175872                    0.008553   \n",
       "max            0.007542  ...          0.693436                    0.220881   \n",
       "\n",
       "       cur_bpfo_1x_lower_sideband  cur_bpfo_harmonic_ratio  \\\n",
       "count                 2792.000000              2792.000000   \n",
       "mean                     0.297987                 0.095571   \n",
       "std                      0.210198                 0.080226   \n",
       "min                      0.016652                 0.000141   \n",
       "25%                      0.117375                 0.028959   \n",
       "50%                      0.236918                 0.062344   \n",
       "75%                      0.481420                 0.185259   \n",
       "max                      0.744812                 0.250326   \n",
       "\n",
       "       cur_spectral_centroid  vib_cur_coherence  window_id      op_freq  \\\n",
       "count            2792.000000        2792.000000  2792.0000  2792.000000   \n",
       "mean              946.278007           0.124409  1395.5000    27.500000   \n",
       "std               105.087835           0.060938   806.1253     5.591171   \n",
       "min               772.918722           0.016882     0.0000    20.000000   \n",
       "25%               844.060068           0.071078   697.7500    23.750000   \n",
       "50%               915.536189           0.111647  1395.5000    27.500000   \n",
       "75%              1056.887578           0.174195  2093.2500    31.250000   \n",
       "max              1121.710932           0.344890  2791.0000    35.000000   \n",
       "\n",
       "              BPFO       label  \n",
       "count  2792.000000  2792.00000  \n",
       "mean     76.283525     0.50000  \n",
       "std      15.509609     0.50009  \n",
       "min      55.478927     0.00000  \n",
       "25%      65.881226     0.00000  \n",
       "50%      76.283525     0.50000  \n",
       "75%      86.685824     1.00000  \n",
       "max      97.088123     1.00000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1396\n",
       "1    1396\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Display dataset information\n",
    "print(\"\\nDataset information:\")\n",
    "display(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataset:\")\n",
    "display(df.isnull().sum())\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Check for the label column\n",
    "if 'label' in df.columns:\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    display(df['label'].value_counts())\n",
    "    \n",
    "    # Visualize label distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.countplot(x='label', data=df)\n",
    "    for i in ax.containers:\n",
    "        ax.bar_label(i)\n",
    "    plt.title('Label Distribution')\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nWarning: No 'label' column found in the dataset. A label column is required for classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ea2fe",
   "metadata": {},
   "source": [
    "## Preprocess Data for PyTorch Neural Network\n",
    "\n",
    "Preprocess the data, including feature scaling, encoding of labels, and splitting into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1235e65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "Data split complete:\n",
      "  Training set: 1674 samples (60.0%)\n",
      "  Validation set: 559 samples (20.0%)\n",
      "  Test set: 559 samples (20.0%)\n",
      "  Feature dimensionality: 35\n",
      "\n",
      "Data successfully prepared for PyTorch neural network training.\n",
      "Input shape: 35 features\n",
      "Number of classes: 2\n",
      "Class names: [0 1]\n"
     ]
    }
   ],
   "source": [
    "def prepare_data_for_pytorch(df):\n",
    "    \"\"\"Prepare the dataset for PyTorch neural network modeling by preprocessing and splitting it.\"\"\"\n",
    "    \n",
    "    # Check if we have a label column for classification\n",
    "    if 'label' not in df.columns:\n",
    "        print(\"Error: No 'label' column found in the dataset. A label column is required for classification.\")\n",
    "        return None, None, None, None, None, None, None, None, None, None\n",
    "    \n",
    "    # Identify features and target\n",
    "    X = df.drop(['label'], axis=1)\n",
    "    \n",
    "    # If window_id doesn't add predictive value, we can drop it\n",
    "    if 'window_id' in X.columns:\n",
    "        X = X.drop(['window_id'], axis=1)\n",
    "    \n",
    "    # Store original feature names for later\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Convert features to numpy array\n",
    "    X = X.values\n",
    "    \n",
    "    # Normalize/standardize the features (important for neural networks)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Get target variable\n",
    "    y = df['label'].values\n",
    "    \n",
    "    # Check if the labels are already numeric\n",
    "    if isinstance(y[0], (str, bool)):\n",
    "        # Encode categorical labels to numbers\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "        class_names = label_encoder.classes_\n",
    "    else:\n",
    "        y_encoded = y\n",
    "        class_names = np.unique(y)\n",
    "    \n",
    "    # Count the number of unique classes\n",
    "    num_classes = len(np.unique(y_encoded))\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # For PyTorch, we'll keep the labels as integers and use CrossEntropyLoss\n",
    "    y_final = y_encoded\n",
    "    \n",
    "    # Split into train, validation, and test sets (60%, 20%, 20%)\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X_scaled, y_final, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    "    )\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    X_val_tensor = torch.FloatTensor(X_val)\n",
    "    X_test_tensor = torch.FloatTensor(X_test)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    y_val_tensor = torch.LongTensor(y_val)\n",
    "    y_test_tensor = torch.LongTensor(y_test)\n",
    "    \n",
    "    print(f\"Data split complete:\")\n",
    "    print(f\"  Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df):.1%})\")\n",
    "    print(f\"  Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(df):.1%})\")\n",
    "    print(f\"  Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df):.1%})\")\n",
    "    print(f\"  Feature dimensionality: {X_train.shape[1]}\")\n",
    "    \n",
    "    return X_train_tensor, X_val_tensor, X_test_tensor, y_train_tensor, y_val_tensor, y_test_tensor, feature_names, scaler, num_classes, class_names\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, feature_names, scaler, num_classes, class_names = prepare_data_for_pytorch(df)\n",
    "\n",
    "# Check if data preparation was successful\n",
    "if X_train is not None:\n",
    "    print(\"\\nData successfully prepared for PyTorch neural network training.\")\n",
    "    print(f\"Input shape: {X_train.shape[1]} features\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485cf81",
   "metadata": {},
   "source": [
    "## Feature Selection Interface\n",
    "\n",
    "Create an interactive interface to select which features to use for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc79f08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6cde521f7d487898ac0e8e8868b507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>Select features to include in the neural network model:</h3>'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_feature_selector(feature_names):\n",
    "    \"\"\"Create interactive widgets for selecting features.\"\"\"\n",
    "    if feature_names is None:\n",
    "        print(\"No feature names available. Cannot create feature selector.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Create checkboxes for each feature\n",
    "    feature_checkboxes = [widgets.Checkbox(value=True, description=f\"{i+1}: {name}\") \n",
    "                          for i, name in enumerate(feature_names)]\n",
    "    \n",
    "    # Create buttons for selecting/deselecting all features\n",
    "    select_all_button = widgets.Button(description=\"Select All\")\n",
    "    deselect_all_button = widgets.Button(description=\"Deselect All\")\n",
    "    select_by_corr_button = widgets.Button(description=\"Select Top 10 by Correlation\")\n",
    "    \n",
    "    # Define button callbacks\n",
    "    def select_all(b):\n",
    "        for checkbox in feature_checkboxes:\n",
    "            checkbox.value = True\n",
    "    \n",
    "    def deselect_all(b):\n",
    "        for checkbox in feature_checkboxes:\n",
    "            checkbox.value = False\n",
    "    \n",
    "    def select_by_correlation(b):\n",
    "        # First deselect all\n",
    "        for checkbox in feature_checkboxes:\n",
    "            checkbox.value = False\n",
    "        \n",
    "        # Try to get correlation values with label\n",
    "        try:\n",
    "            corr_values = df[feature_names].corrwith(df['label']).abs().sort_values(ascending=False)\n",
    "            top_features = corr_values.head(10).index.tolist()  # Take top 10 for neural network\n",
    "            \n",
    "            # Select top features by correlation with label\n",
    "            for checkbox in feature_checkboxes:\n",
    "                feature_name = checkbox.description.split(\": \")[1]\n",
    "                if feature_name in top_features:\n",
    "                    checkbox.value = True\n",
    "            \n",
    "            print(f\"Selected top 10 features by correlation with label: {', '.join(top_features)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error selecting by correlation: {e}\")\n",
    "            # If there's an error, just select the first 10 features\n",
    "            for i, checkbox in enumerate(feature_checkboxes):\n",
    "                if i < 10:\n",
    "                    checkbox.value = True\n",
    "    \n",
    "    # Attach callbacks to buttons\n",
    "    select_all_button.on_click(select_all)\n",
    "    deselect_all_button.on_click(deselect_all)\n",
    "    select_by_corr_button.on_click(select_by_correlation)\n",
    "    \n",
    "    # Create layout for the feature selection UI\n",
    "    button_box = widgets.HBox([select_all_button, deselect_all_button, select_by_corr_button])\n",
    "    checkbox_box = widgets.VBox(feature_checkboxes)\n",
    "    feature_selector = widgets.VBox([\n",
    "        widgets.HTML(value=\"<h3>Select features to include in the neural network model:</h3>\"),\n",
    "        button_box,\n",
    "        checkbox_box\n",
    "    ])\n",
    "    \n",
    "    return feature_selector, feature_checkboxes\n",
    "\n",
    "# Create neural network parameter widgets\n",
    "hidden_layers_widget = widgets.IntSlider(\n",
    "    value=2, min=1, max=5, step=1,\n",
    "    description='Hidden Layers:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "neurons_per_layer_widget = widgets.IntSlider(\n",
    "    value=64, min=8, max=256, step=8,\n",
    "    description='Neurons per Layer:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "dropout_rate_widget = widgets.FloatSlider(\n",
    "    value=0.2, min=0.0, max=0.5, step=0.05,\n",
    "    description='Dropout Rate:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "learning_rate_widget = widgets.FloatLogSlider(\n",
    "    value=0.001, base=10, min=-4, max=-2, step=0.2,\n",
    "    description='Learning Rate:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "batch_size_widget = widgets.IntSlider(\n",
    "    value=32, min=8, max=128, step=8,\n",
    "    description='Batch Size:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "epochs_widget = widgets.IntSlider(\n",
    "    value=50, min=10, max=200, step=10,\n",
    "    description='Max Epochs:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "activation_widget = widgets.Dropdown(\n",
    "    options=['relu', 'elu', 'tanh', 'sigmoid'],\n",
    "    value='relu',\n",
    "    description='Activation:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Create the feature selector if features are available\n",
    "if feature_names:\n",
    "    feature_selector, feature_checkboxes = create_feature_selector(feature_names)\n",
    "    display(widgets.VBox([\n",
    "        feature_selector,\n",
    "        widgets.HTML(value=\"<h3>Neural Network Parameters:</h3>\"),\n",
    "        hidden_layers_widget,\n",
    "        neurons_per_layer_widget,\n",
    "        activation_widget,\n",
    "        dropout_rate_widget,\n",
    "        learning_rate_widget,\n",
    "        batch_size_widget,\n",
    "        epochs_widget\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3241e",
   "metadata": {},
   "source": [
    "## Define the PyTorch Neural Network Model\n",
    "\n",
    "Define a PyTorch neural network model class with customizable architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2464d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"PyTorch neural network model with customizable architecture.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_layers, neurons_per_layer, dropout_rate, activation_func, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        # Map activation function string to PyTorch activation function\n",
    "        activation_map = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'elu': nn.ELU(),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'sigmoid': nn.Sigmoid()\n",
    "        }\n",
    "        activation = activation_map[activation_func]\n",
    "        \n",
    "        # Create list to hold all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
    "        layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
    "        layers.append(activation)\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers.append(nn.Linear(neurons_per_layer, neurons_per_layer))\n",
    "            layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
    "            layers.append(activation)\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(neurons_per_layer, num_classes))\n",
    "        \n",
    "        # Create sequential model with all layers\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031b3f8",
   "metadata": {},
   "source": [
    "## Train the Neural Network Model\n",
    "\n",
    "Create a function to train the PyTorch neural network model with selected features and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6754d087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2362efec3e4b4d059741207b082e6495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Train Neural Network', layout=Layout(height='40px', width='200px')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adcf01c3e234586b47bf7dc765d00ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_pytorch_network(feature_checkboxes, hidden_layers, neurons_per_layer, activation,\n",
    "                          dropout_rate, learning_rate, batch_size, epochs):\n",
    "    \"\"\"Train a PyTorch neural network model with the selected features and parameters.\"\"\"\n",
    "    if X_train is None or y_train is None:\n",
    "        print(\"Error: Training data not available.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Get selected feature indices\n",
    "    selected_indices = []\n",
    "    selected_features = []\n",
    "    \n",
    "    for i, checkbox in enumerate(feature_checkboxes):\n",
    "        if checkbox.value:\n",
    "            selected_indices.append(i)\n",
    "            feature_name = checkbox.description.split(\": \")[1]\n",
    "            selected_features.append(feature_name)\n",
    "    \n",
    "    if not selected_indices:\n",
    "        print(\"Error: No features selected. Please select at least one feature.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(f\"\\nTraining neural network with {len(selected_indices)} selected features:\")\n",
    "    for i, feature in enumerate(selected_features):\n",
    "        print(f\"  {i+1}. {feature}\")\n",
    "    \n",
    "    # Select the features\n",
    "    X_train_selected = X_train[:, selected_indices]\n",
    "    X_val_selected = X_val[:, selected_indices]\n",
    "    X_test_selected = X_test[:, selected_indices]\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(X_train_selected, y_train)\n",
    "    val_dataset = TensorDataset(X_val_selected, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Initialize the model\n",
    "    input_dim = len(selected_indices)\n",
    "    model = NeuralNetwork(\n",
    "        input_dim=input_dim,\n",
    "        hidden_layers=hidden_layers,\n",
    "        neurons_per_layer=neurons_per_layer,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation_func=activation,\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "    \n",
    "    # Display model structure\n",
    "    print(\"\\nModel Structure:\")\n",
    "    print(model)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # LR scheduler for reducing learning rate when validation loss plateaus\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "    \n",
    "    # Initialize variables to track training process\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    early_stopping_patience = 15\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Training loop\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(train_dataset)\n",
    "        epoch_train_acc = correct / total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_val_loss = running_loss / len(val_dataset)\n",
    "        epoch_val_acc = correct / total\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "        \n",
    "        # Update learning rate based on validation loss\n",
    "        scheduler.step(epoch_val_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}: \"\n",
    "                  f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, \"\n",
    "                  f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    print(\"\\nTraining complete.\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Training')\n",
    "    plt.plot(val_accuracies, label='Validation')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_selected.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_accuracy = (predicted == y_test.to(device)).sum().item() / len(y_test)\n",
    "    \n",
    "    print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }, selected_indices\n",
    "\n",
    "# Create a button to train the model\n",
    "train_button = widgets.Button(\n",
    "    description=\"Train Neural Network\",\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "# Define the callback for the train button\n",
    "output = widgets.Output()\n",
    "\n",
    "@output.capture()\n",
    "def on_train_button_clicked(b):\n",
    "    if 'feature_checkboxes' not in globals():\n",
    "        print(\"Error: Feature checkboxes not initialized.\")\n",
    "        return\n",
    "    \n",
    "    model, history, selected_indices = train_pytorch_network(\n",
    "        feature_checkboxes,\n",
    "        hidden_layers_widget.value,\n",
    "        neurons_per_layer_widget.value,\n",
    "        activation_widget.value,\n",
    "        dropout_rate_widget.value,\n",
    "        learning_rate_widget.value,\n",
    "        batch_size_widget.value,\n",
    "        epochs_widget.value\n",
    "    )\n",
    "    \n",
    "    if model is not None:\n",
    "        # Store the model and selected indices as global variables for later use\n",
    "        global pytorch_model, pytorch_history, pytorch_selected_indices\n",
    "        pytorch_model = model\n",
    "        pytorch_history = history\n",
    "        pytorch_selected_indices = selected_indices\n",
    "\n",
    "# Connect the callback to the button\n",
    "train_button.on_click(on_train_button_clicked)\n",
    "\n",
    "# Display the button and output area\n",
    "display(train_button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c96da6",
   "metadata": {},
   "source": [
    "## Evaluate the Neural Network Model on the Test Set\n",
    "\n",
    "Evaluate the trained PyTorch neural network model on the test set and display detailed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ac8c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01e9f3fa37d4f53898b6c56bc4604ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Evaluate Neural Network', layout=Layout(height='40px', width='200px')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1135ffd39cf4f35be5cb063c099ab22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_pytorch_model():\n",
    "    \"\"\"Evaluate the trained PyTorch neural network on the test set\"\"\"\n",
    "    if 'pytorch_model' not in globals() or 'pytorch_selected_indices' not in globals():\n",
    "        print(\"Error: No trained model available. Please train a model first.\")\n",
    "        return\n",
    "    \n",
    "    # Get the trained model and selected indices\n",
    "    model = pytorch_model\n",
    "    selected_indices = pytorch_selected_indices\n",
    "    \n",
    "    # Select the features from the test set\n",
    "    X_test_selected = X_test[:, selected_indices].to(device)\n",
    "    y_test_cpu = y_test.clone().cpu()\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_selected)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_cpu = predicted.cpu()\n",
    "        test_accuracy = (predicted.cpu() == y_test_cpu).sum().item() / len(y_test_cpu)\n",
    "    \n",
    "    print(f\"Neural Network Evaluation on Test Set:\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nTest Set Classification Report:\")\n",
    "    print(classification_report(y_test_cpu, predicted_cpu))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"\\nTest Set Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test_cpu, predicted_cpu)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix (Test Set)')\n",
    "    plt.show()\n",
    "    \n",
    "    # If multi-class, visualize class-wise performance\n",
    "    if num_classes > 2:\n",
    "        # Compute per-class accuracy\n",
    "        per_class_accuracy = []\n",
    "        for i in range(num_classes):\n",
    "            class_indices = (y_test_cpu == i)\n",
    "            if class_indices.sum().item() > 0:  # Avoid division by zero\n",
    "                accuracy = (predicted_cpu[class_indices] == i).sum().item() / class_indices.sum().item()\n",
    "                per_class_accuracy.append(accuracy)\n",
    "            else:\n",
    "                per_class_accuracy.append(0)\n",
    "        \n",
    "        # Plot per-class accuracy\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=list(range(num_classes)), y=per_class_accuracy)\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Per-Class Accuracy')\n",
    "        plt.ylim(0, 1.0)\n",
    "        plt.show()\n",
    "\n",
    "# Create a button to evaluate the model\n",
    "eval_button = widgets.Button(\n",
    "    description=\"Evaluate Neural Network\",\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "# Define the callback for the evaluation button\n",
    "eval_output = widgets.Output()\n",
    "\n",
    "@eval_output.capture()\n",
    "def on_eval_button_clicked(b):\n",
    "    evaluate_pytorch_model()\n",
    "\n",
    "# Connect the callback to the button\n",
    "eval_button.on_click(on_eval_button_clicked)\n",
    "\n",
    "# Display the button and output area\n",
    "display(eval_button)\n",
    "display(eval_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1321019",
   "metadata": {},
   "source": [
    "## Save the Trained Model\n",
    "\n",
    "Save the trained PyTorch neural network model and selected features for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9718972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5efe5546fd44f648bb703be2a343824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Save Neural Network', layout=Layout(height='40px', width='200px'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2b874b40f84036b834a1900d87a6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_pytorch_model():\n",
    "    \"\"\"Save the trained PyTorch neural network model and selected features\"\"\"\n",
    "    if 'pytorch_model' not in globals() or 'pytorch_selected_indices' not in globals():\n",
    "        print(\"Error: No trained model available. Please train a model first.\")\n",
    "        return\n",
    "    \n",
    "    # Create a directory for models if it doesn't exist\n",
    "    model_dir = os.path.join(os.path.dirname(file_path), 'models')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(model_dir, 'pytorch_neural_network.pt')\n",
    "    torch.save(pytorch_model.state_dict(), model_path)\n",
    "    \n",
    "    # Save the selected feature indices\n",
    "    features_path = os.path.join(model_dir, 'pytorch_selected_features.txt')\n",
    "    selected_features = [feature_names[i] for i in pytorch_selected_indices]\n",
    "    with open(features_path, 'w') as f:\n",
    "        f.write('\\n'.join(selected_features))\n",
    "    \n",
    "    # Save the scaler for later use\n",
    "    scaler_path = os.path.join(model_dir, 'pytorch_scaler.joblib')\n",
    "    import joblib\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    \n",
    "    # Save model architecture parameters for later reconstruction\n",
    "    model_config = {\n",
    "        'input_dim': len(pytorch_selected_indices),\n",
    "        'hidden_layers': hidden_layers_widget.value,\n",
    "        'neurons_per_layer': neurons_per_layer_widget.value,\n",
    "        'dropout_rate': dropout_rate_widget.value,\n",
    "        'activation_func': activation_widget.value,\n",
    "        'num_classes': num_classes\n",
    "    }\n",
    "    \n",
    "    config_path = os.path.join(model_dir, 'pytorch_model_config.joblib')\n",
    "    joblib.dump(model_config, config_path)\n",
    "    \n",
    "    print(f\"PyTorch model saved to: {model_path}\")\n",
    "    print(f\"Selected features saved to: {features_path}\")\n",
    "    print(f\"Feature scaler saved to: {scaler_path}\")\n",
    "    print(f\"Model configuration saved to: {config_path}\")\n",
    "    print(\"\\nTo load the model later, use:\")\n",
    "    print(\"```python\")\n",
    "    print(\"import torch\")\n",
    "    print(\"import joblib\")\n",
    "    print(\"from torch import nn\")\n",
    "    print(\"\")\n",
    "    print(\"# Load model configuration\")\n",
    "    print(\"config = joblib.load('path/to/pytorch_model_config.joblib')\")\n",
    "    print(\"\")\n",
    "    print(\"# Recreate the model architecture\")\n",
    "    print(\"model = NeuralNetwork(**config)\")\n",
    "    print(\"\")\n",
    "    print(\"# Load the saved weights\")\n",
    "    print(\"model.load_state_dict(torch.load('path/to/pytorch_neural_network.pt'))\")\n",
    "    print(\"model.eval()  # Set to evaluation mode\")\n",
    "    print(\"```\")\n",
    "\n",
    "# Create a button to save the model\n",
    "save_button = widgets.Button(\n",
    "    description=\"Save Neural Network\",\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "# Define the callback for the save button\n",
    "save_output = widgets.Output()\n",
    "\n",
    "@save_output.capture()\n",
    "def on_save_button_clicked(b):\n",
    "    save_pytorch_model()\n",
    "\n",
    "# Connect the callback to the button\n",
    "save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "# Display the button and output area\n",
    "display(save_button)\n",
    "display(save_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe810a32",
   "metadata": {},
   "source": [
    "## Compare with Simple Baseline Models\n",
    "\n",
    "Compare the PyTorch neural network with simple baseline models to assess the value of the neural network approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620a471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3ec5efd30b41399ee6ffa5295d76c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Compare with Baselines', layout=Layout(height='40px', width='200px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1d0cae4abb4f858db63c9e79d5421e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_baseline_models():\n",
    "    \"\"\"Create simple baseline models for comparison\"\"\"\n",
    "    if 'pytorch_selected_indices' not in globals() or 'pytorch_model' not in globals():\n",
    "        print(\"Error: Neural network not trained yet. Please train a neural network first.\")\n",
    "        return\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_indices = pytorch_selected_indices\n",
    "    X_train_np = X_train[:, selected_indices].numpy()\n",
    "    X_test_np = X_test[:, selected_indices].numpy()\n",
    "    y_train_np = y_train.numpy()\n",
    "    y_test_np = y_test.numpy()\n",
    "    \n",
    "    print(\"Creating baseline models for comparison...\")\n",
    "    \n",
    "    # 1. Decision Tree\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    dt_model.fit(X_train_np, y_train_np)\n",
    "    dt_score = dt_model.score(X_test_np, y_test_np)\n",
    "    \n",
    "    # 2. Random Forest\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_np, y_train_np)\n",
    "    rf_score = rf_model.score(X_test_np, y_test_np)\n",
    "    \n",
    "    # 3. Support Vector Machine\n",
    "    from sklearn.svm import SVC\n",
    "    svm_model = SVC(random_state=42)\n",
    "    svm_model.fit(X_train_np, y_train_np)\n",
    "    svm_score = svm_model.score(X_test_np, y_test_np)\n",
    "    \n",
    "    # 4. Neural Network (already trained)\n",
    "    pytorch_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = pytorch_model(X_test[:, selected_indices].to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        nn_score = (predicted.cpu() == y_test).sum().item() / len(y_test)\n",
    "    \n",
    "    # Compare models\n",
    "    print(\"\\nModel Comparison (Test Accuracy):\")\n",
    "    print(f\"Decision Tree: {dt_score:.4f}\")\n",
    "    print(f\"Random Forest: {rf_score:.4f}\")\n",
    "    print(f\"Support Vector Machine: {svm_score:.4f}\")\n",
    "    print(f\"PyTorch Neural Network: {nn_score:.4f}\")\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    models = ['Decision Tree', 'Random Forest', 'SVM', 'Neural Network']\n",
    "    scores = [dt_score, rf_score, svm_score, nn_score]\n",
    "    \n",
    "    # Create bar plot\n",
    "    ax = sns.barplot(x=models, y=scores)\n",
    "    plt.ylim(max(0, min(scores) - 0.1), min(1.0, max(scores) + 0.1))\n",
    "    plt.title('Model Comparison')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    \n",
    "    # Add labels to bars\n",
    "    for i, score in enumerate(scores):\n",
    "        ax.text(i, score - 0.05, f\"{score:.4f}\", ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a button to compare models\n",
    "compare_button = widgets.Button(\n",
    "    description=\"Compare with Baselines\",\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "# Define the callback for the comparison button\n",
    "compare_output = widgets.Output()\n",
    "\n",
    "@compare_output.capture()\n",
    "def on_compare_button_clicked(b):\n",
    "    create_baseline_models()\n",
    "\n",
    "# Connect the callback to the button\n",
    "compare_button.on_click(on_compare_button_clicked)\n",
    "\n",
    "# Display the button and output area\n",
    "display(compare_button)\n",
    "display(compare_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023a6abe",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provided a complete workflow for building, training, evaluating, and saving a PyTorch neural network model using the FFT features dataset. Key features include:\n",
    "\n",
    "1. Interactive feature selection to choose which features to use in training\n",
    "2. Customizable neural network architecture (layers, neurons, activation functions, etc.)\n",
    "3. Detailed model evaluation with accuracy metrics and visualizations\n",
    "4. Comparison with baseline models to assess the neural network's performance\n",
    "5. Data split into training (60%), validation (20%), and test (20%) sets with random shuffling\n",
    "\n",
    "The PyTorch neural network approach provides a powerful and flexible method for classifying data from the FFT features dataset, potentially capturing complex patterns that simpler models might miss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
